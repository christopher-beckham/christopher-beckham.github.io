Bibliography.bib@misc{zhang2022unifying,
      title={Unifying Likelihood-free Inference with Black-box Optimization and Beyond}, 
      author={Dinghuai Zhang and Jie Fu and Yoshua Bengio and Aaron Courville},
      year={2022},
      eprint={2110.03372},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{fannjiang2022conformal,
      title={Conformal prediction for the design problem}, 
      author={Clara Fannjiang and Stephen Bates and Anastasios N. Angelopoulos and Jennifer Listgarten and Michael I. Jordan},
      year={2022},
      eprint={2202.03613},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{trabucco2022designbench,
  title={Design-bench: Benchmarks for data-driven offline model-based optimization},
  author={Trabucco, Brandon and Geng, Xinyang and Kumar, Aviral and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={21658--21676},
  year={2022},
  organization={PMLR}
}

@inproceedings{trabucco2021conservative,
  title={Conservative objective models for effective offline model-based optimization},
  author={Trabucco, Brandon and Kumar, Aviral and Geng, Xinyang and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={10358--10368},
  year={2021},
  organization={PMLR}
}


@article{sun2021amortized,
  title={Amortized Synthesis of Constrained Configurations Using a Differentiable Surrogate},
  author={Sun, Xingyuan and Xue, Tianju and Rusinkiewicz, Szymon and Adams, Ryan P},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}
@article{kumar2021data,
  title={Data-Driven Offline Optimization For Architecting Hardware Accelerators},
  author={Kumar, Aviral and Yazdanbakhsh, Amir and Hashemi, Milad and Swersky, Kevin and Levine, Sergey},
  journal={arXiv preprint arXiv:2110.11346},
  year={2021}
}


@book{butler2007saddlepoint,
  title={Saddlepoint approximations with applications},
  author={Butler, Ronald W},
  volume={22},
  year={2007},
  publisher={Cambridge University Press}
}

@article{fannjiang2020autofocused,
  title={Autofocused oracles for model-based design},
  author={Fannjiang, Clara and Listgarten, Jennifer},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={12945--12956},
  year={2020},
  tags={mbo}
}

@article{qi2022data,
  title={Data-Driven Offline Decision-Making via Invariant Representation Learning},
  author={Qi, Han and Su, Yi and Kumar, Aviral and Levine, Sergey},
  journal={arXiv preprint arXiv:2211.11349},
  year={2022},
  tags={mbo, iom, domain adaptation},
  File={~/Dropbox/Edge/mbo/iom.pdf}
}

@article{brockman2016openai,
  title={Openai gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}

@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ international conference on intelligent robots and systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}

@article{mins,
  title={Model inversion networks for model-based optimization},
  author={Kumar, Aviral and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={5126--5137},
  year={2020}
}

@article{dieng2019prescribed,
  title={Prescribed generative adversarial networks},
  author={Dieng, Adji B and Ruiz, Francisco JR and Blei, David M and Titsias, Michalis K},
  journal={arXiv preprint arXiv:1910.04302},
  year={2019}
}

@article{miyato,
  title={{cGANs} with projection discriminator},
  author={Miyato, Takeru and Koyama, Masanori},
  journal={arXiv preprint arXiv:1802.05637},
  year={2018}
}

@inproceedings{brookes2019conditioning,
  title={Conditioning by adaptive sampling for robust design},
  author={Brookes, David and Park, Hahnbeom and Listgarten, Jennifer},
  booktitle={International conference on machine learning},
  pages={773--782},
  year={2019},
  organization={PMLR}
}

@misc{nair2020mip,
  doi = {10.48550/ARXIV.2012.13349},
  
  url = {https://arxiv.org/abs/2012.13349},
  
  author = {Nair, Vinod and Bartunov, Sergey and Gimeno, Felix and von Glehn, Ingrid and Lichocki, Pawel and Lobov, Ivan and O'Donoghue, Brendan and Sonnerat, Nicolas and Tjandraatmadja, Christian and Wang, Pengming and Addanki, Ravichandra and Hapuarachchi, Tharindi and Keck, Thomas and Keeling, James and Kohli, Pushmeet and Ktena, Ira and Li, Yujia and Vinyals, Oriol and Zwols, Yori},
  
  keywords = {Optimization and Control (math.OC), Artificial Intelligence (cs.AI), Discrete Mathematics (cs.DM), Machine Learning (cs.LG), Neural and Evolutionary Computing (cs.NE), FOS: Mathematics, FOS: Mathematics, FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Solving Mixed Integer Programs Using Neural Networks},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}



@article{ncsns,
  title={Improved techniques for training score-based generative models},
  author={Song, Yang and Ermon, Stefano},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={12438--12448},
  year={2020}
}

@article{levine2020offline,
  title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}
@inproceedings{kostrikov2021offline,
  title={Offline reinforcement learning with fisher divergence critic regularization},
  author={Kostrikov, Ilya and Fergus, Rob and Tompson, Jonathan and Nachum, Ofir},
  booktitle={International Conference on Machine Learning},
  pages={5774--5783},
  year={2021},
  organization={PMLR}
}
@article{wu2019behavior,
  title={Behavior regularized offline reinforcement learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}
@article{kumar2020conservative,
  title={Conservative q-learning for offline reinforcement learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1179--1191},
  year={2020}
}
@article{fujimoto2021minimalist,
  title={A minimalist approach to offline reinforcement learning},
  author={Fujimoto, Scott and Gu, Shixiang Shane},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={20132--20145},
  year={2021}
}
@article{ttur,
  author    = {Martin Heusel and Hubert Ramsauer and Thomas Unterthiner and Bernhard Nessler and Gunter Klambauer and Sepp Hochreiter},
  title     = {{GANs} Trained by a Two Time-Scale Update Rule Converge to a {Nash} Equilibrium},
  journal   = {CoRR},
  volume    = {abs/1706.08500},
  year      = {2017},
  url       = {http://arxiv.org/abs/1706.08500},
  eprinttype = {arXiv},
  eprint    = {1706.08500},
  timestamp = {Sat, 23 Jan 2021 01:20:58 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/HeuselRUNKH17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{dowson1982frechet,
  title={The {Fr{\'e}chet} distance between multivariate normal distributions},
  author={Dowson, DC and Landau, BV666017},
  journal={Journal of multivariate analysis},
  volume={12},
  number={3},
  pages={450--455},
  year={1982},
  publisher={Elsevier}
}

@inproceedings{yaz2018unusual,
  title={The unusual effectiveness of averaging in GAN training},
  author={Yaz, Yasin and Foo, Chuan-Sheng and Winkler, Stefan and Yap, Kim-Hui and Piliouras, Georgios and Chandrasekhar, Vijay and others},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@article{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},

  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}


@article{sohn2015learning,
  title={Learning structured output representation using deep conditional generative models},
  author={Sohn, Kihyuk and Lee, Honglak and Yan, Xinchen},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@article{kingma2013auto,
  title={Auto-encoding variational {Bayes}},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@inproceedings{welling2011bayesian,
  title={Bayesian learning via stochastic gradient Langevin dynamics},
  author={Welling, Max and Teh, Yee W},
  booktitle={Proceedings of the 28th international conference on machine learning (ICML-11)},
  pages={681--688},
  year={2011},
  tags={sgld, langevin, mcmc},
  File={~/Dropbox/Edge/theory/sgld.pdf}
}

@article{piche2022implicit,
  title={Implicit Offline Reinforcement Learning via Supervised Learning},
  author={Piche, Alexandre and Pardinas, Rafael and Vazquez, David and Mordatch, Igor and Pal, Chris},
  journal={arXiv preprint arXiv:2210.12272},
  year={2022}
}


@article{sajjadi2018assessing,
  title={Assessing generative models via precision and recall},
  author={Sajjadi, Mehdi SM and Bachem, Olivier and Lucic, Mario and Bousquet, Olivier and Gelly, Sylvain},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}



@article{hamidieh2018data,
  title={A data-driven statistical model for predicting the critical temperature of a superconductor},
  author={Hamidieh, Kam},
  journal={Computational Materials Science},
  volume={154},
  pages={346--354},
  year={2018},
  publisher={Elsevier}
}

@article{karras2022elucidating,
  title={Elucidating the design space of diffusion-based generative models},
  author={Karras, Tero and Aittala, Miika and Aila, Timo and Laine, Samuli},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={26565--26577},
  year={2022}
}

@article{kynkaanniemi2019improved,
  title={Improved precision and recall metric for assessing generative models},
  author={Kynk{\"a}{\"a}nniemi, Tuomas and Karras, Tero and Laine, Samuli and Lehtinen, Jaakko and Aila, Timo},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{song2020score,
  title={Score-based generative modeling through stochastic differential equations},
  author={Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
  journal={arXiv preprint arXiv:2011.13456},
  year={2020}
}


@article{song2019generative,
  title={Generative modeling by estimating gradients of the data distribution},
  author={Song, Yang and Ermon, Stefano},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

@inproceedings{rezende2015variational,
  title={Variational inference with normalizing flows},
  author={Rezende, Danilo and Mohamed, Shakir},
  booktitle={International conference on machine learning},
  pages={1530--1538},
  year={2015},
  organization={PMLR}
}

@article{kingma2018glow,
  title={Glow: Generative flow with invertible 1x1 convolutions},
  author={Kingma, Durk P and Dhariwal, Prafulla},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@inproceedings{naeem2020reliable,
  title={Reliable fidelity and diversity metrics for generative models},
  author={Naeem, Muhammad Ferjad and Oh, Seong Joon and Uh, Youngjung and Choi, Yunjey and Yoo, Jaejun},
  booktitle={International Conference on Machine Learning},
  pages={7176--7185},
  year={2020},
  organization={PMLR}
}

@book{asmussen2007stochastic,
  title={Stochastic simulation: algorithms and analysis},
  author={Asmussen, S{\o}ren and Glynn, Peter W},
  volume={57},
  year={2007},
  publisher={Springer}
}

@article{o2020making,
  title={Making sense of reinforcement learning and probabilistic inference},
  author={O'Donoghue, Brendan and Osband, Ian and Ionescu, Catalin},
  journal={arXiv preprint arXiv:2001.00805},
  year={2020}
}


@article{borji2022pros,
  title={Pros and cons of {GAN} evaluation measures: New developments},
  author={Borji, Ali},
  journal={Computer Vision and Image Understanding},
  volume={215},
  pages={103329},
  year={2022},
  publisher={Elsevier}
}

@article{barrera2016survey,
  title={Survey of variation in human transcription factors reveals prevalent {DNA} binding changes},
  author={Barrera, Luis A and Vedenko, Anastasia and Kurland, Jesse V and Rogers, Julia M and Gisselbrecht, Stephen S and Rossin, Elizabeth J and Woodard, Jaie and Mariani, Luca and Kock, Kian Hong and Inukai, Sachi and others},
  journal={Science},
  volume={351},
  number={6280},
  pages={1450--1454},
  year={2016},
  publisher={American Association for the Advancement of Science}
}

@article{gumbel_softmax,
  title={Categorical reparameterization with {Gumbel-Softmax}},
  author={Jang, Eric and Gu, Shixiang and Poole, Ben},
  journal={arXiv preprint arXiv:1611.01144},
  year={2016}
}

@article{colinblog,
    title={{GANs} and divergence minimization},
    author={Colin Raffel},
    journal={Personal blog},
    year={2018},
    url={https://colinraffel.com/blog/gans-and-divergence-minimization.html}
}

@article{ghojogh2021factor,
  title={Factor analysis, probabilistic principal component analysis, variational inference, and variational autoencoder: Tutorial and survey},
  author={Ghojogh, Benyamin and Ghodsi, Ali and Karray, Fakhri and Crowley, Mark},
  journal={arXiv preprint arXiv:2101.00734},
  year={2021}
}

@article{liu2020retrognn,
  title={RetroGNN: Approximating retrosynthesis by graph neural networks for de novo drug design},
  author={Liu, Cheng-Hao and Korablyov, Maksym and Jastrz{\k{e}}bski, Stanis{\l}aw and W{\l}odarczyk-Pruszy{\'n}ski, Pawe{\l} and Bengio, Yoshua and Segler, Marwin HS},
  journal={arXiv preprint arXiv:2011.13042},
  year={2020}
}

@article{lopez2016revisiting,
  title={Revisiting classifier two-sample tests},
  author={Lopez-Paz, David and Oquab, Maxime},
  journal={arXiv preprint arXiv:1610.06545},
  year={2016}
}


@article{classifierfree,
  title={Classifier-free diffusion guidance},
  author={Ho, Jonathan and Salimans, Tim},
  journal={arXiv preprint arXiv:2207.12598},
  year={2022}
}

@article{dhariwal2021diffusion,
  title={Diffusion models beat gans on image synthesis},
  author={Dhariwal, Prafulla and Nichol, Alexander},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={8780--8794},
  year={2021}
}

@inproceedings{lu2022conditional,
  title={Conditional diffusion probabilistic model for speech enhancement},
  author={Lu, Yen-Ju and Wang, Zhong-Qiu and Watanabe, Shinji and Richard, Alexander and Yu, Cheng and Tsao, Yu},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7402--7406},
  year={2022},
  organization={IEEE}
}

@article{huang2017adversarial,
  title={Adversarial divergences are good task losses for generative modeling},
  author={Huang, Gabriel and Gidel, Gauthier and Berard, Hugo and Touati, Ahmed and Lacoste-Julien, Simon},
  journal={arXiv preprint arXiv:1708.02511},
  year={2017}
}

@article{nowozin2016f,
  title={f-gan: Training generative neural samplers using variational divergence minimization},
  author={Nowozin, Sebastian and Cseke, Botond and Tomioka, Ryota},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@article{weng2021diffusion,
  title   = "What are diffusion models?",
  author  = "Weng, Lilian",
  journal = "lilianweng.github.io",
  year    = "2021",
  month   = "Jul",
  url     = "https://lilianweng.github.io/posts/2021-07-11-diffusion-models/"
}

@article{huszar2015not,
  title={How (not) to train your generative model: Scheduled sampling, likelihood, adversary?},
  author={Husz{\'a}r, Ferenc},
  journal={arXiv preprint arXiv:1511.05101},
  year={2015}
}

@article{theis2015note,
  title={A note on the evaluation of generative models},
  author={Theis, Lucas and Oord, A{\"a}ron van den and Bethge, Matthias},
  journal={arXiv preprint arXiv:1511.01844},
  year={2015}
}

@article{dosovitskiy2016generating,
  title={Generating images with perceptual similarity metrics based on deep networks},
  author={Dosovitskiy, Alexey and Brox, Thomas},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@article{huang2017parametric,
  title={Parametric Adversarial Divergences are Good Losses for Generative Modeling},
  author={Huang, Gabriel and Berard, Hugo and Touati, Ahmed and Gidel, Gauthier and Vincent, Pascal and Lacoste-Julien, Simon},
  journal={arXiv preprint arXiv:1708.02511},
  year={2017}
}

@article{brock2018large,
  title={Large scale GAN training for high fidelity natural image synthesis},
  author={Brock, Andrew and Donahue, Jeff and Simonyan, Karen},
  journal={arXiv preprint arXiv:1809.11096},
  year={2018}
}

@article{burgess2018understanding,
  title={Understanding disentangling in Beta-VAE},
  author={Burgess, Christopher P and Higgins, Irina and Pal, Arka and Matthey, Loic and Watters, Nick and Desjardins, Guillaume and Lerchner, Alexander},
  journal={arXiv preprint arXiv:1804.03599},
  year={2018}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@inproceedings{chen2022bidirectional,
 author = {Chen, Can and Zhang, Yingxueff and Fu, Jie and Liu, Xue (Steve) and Coates, Mark},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {29454--29467},
 publisher = {Curran Associates, Inc.},
 title = {Bidirectional Learning for Offline Infinite-width Model-based Optimization},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/bd391cf5bdc4b63674d6da3edc1bde0d-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}

@article{fu2021offline,
  title={Offline model-based optimization via normalized maximum likelihood estimation},
  author={Fu, Justin and Levine, Sergey},
  journal={arXiv preprint arXiv:2102.07970},
  year={2021},
  tags={mbo}
}

@article{yu2021roma,
  title={Roma: Robust model adaptation for offline model-based optimization},
  author={Yu, Sihyun and Ahn, Sungsoo and Song, Le and Shin, Jinwoo},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={4619--4631},
  year={2021},
  File={~/Dropbox/Edge/mbo/roma.pdf}
}


@article{song2020improved,
  title={Improved techniques for training score-based generative models},
  author={Song, Yang and Ermon, Stefano},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={12438--12448},
  year={2020},
  tags={sbgm, diffusion, song},
  File={~/Dropbox/Edge/ddpms/sbgm-improved-techniques.pdf}
}

@article{wilson2017reparameterization,
  title={The reparameterization trick for acquisition functions},
  author={Wilson, James T and Moriconi, Riccardo and Hutter, Frank and Deisenroth, Marc Peter},
  journal={arXiv preprint arXiv:1712.00424},
  year={2017}
}

@inproceedings{sohl2015deep,
  title={Deep unsupervised learning using nonequilibrium thermodynamics},
  author={Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
  booktitle={International conference on machine learning},
  pages={2256--2265},
  year={2015},
  organization={PMLR},
  tags={ddpms, score matching}
}

@article{hakhamaneshi2021jumbo,
  title={Jumbo: Scalable multi-task bayesian optimization using offline data},
  author={Hakhamaneshi, Kourosh and Abbeel, Pieter and Stojanovic, Vladimir and Grover, Aditya},
  journal={arXiv preprint arXiv:2106.00942},
  year={2021},
  File={~/Dropbox/Edge/mbo/jumbo.pdf},
  tags={mbo, bayesopt, bayesian optimisation}
}


@article{wang2021pre,
  title={Pre-trained Gaussian processes for Bayesian optimization},
  author={Wang, Zi and Dahl, George E and Swersky, Kevin and Lee, Chansoo and Mariet, Zelda and Nado, Zachary and Gilmer, Justin and Snoek, Jasper and Ghahramani, Zoubin},
  journal={arXiv preprint arXiv:2109.08215},
  year={2021},
  File={~/Dropbox/Edge/bb-opt/pretrained-bo.pdf}
}

@inproceedings{wistuba2021few,
  title={Few-Shot Bayesian Optimization with Deep Kernel Surrogates},
  author={Wistuba, Martin and Grabocka, Josif},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@article{chen2022towards,
  title={Towards learning universal hyperparameter optimizers with transformers},
  author={Chen, Yutian and Song, Xingyou and Lee, Chansoo and Wang, Zi and Zhang, Richard and Dohan, David and Kawakami, Kazuya and Kochanski, Greg and Doucet, Arnaud and Ranzato, Marc'aurelio and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={32053--32068},
  year={2022}
}


@article{maus2022local,
  title={Local latent space bayesian optimization over structured inputs},
  author={Maus, Natalie and Jones, Haydn and Moore, Juston and Kusner, Matt J and Bradshaw, John and Gardner, Jacob},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={34505--34518},
  year={2022}
}

@article{vapnik1991principles,
  title={Principles of risk minimization for learning theory},
  author={Vapnik, Vladimir},
  journal={Advances in neural information processing systems},
  volume={4},
  year={1991}
}