#+TITLE: My notes on discrete denoising diffusion models
#+LATEX_HEADER: \newcommand{\xx}{\boldsymbol{x}}
#+LATEX_HEADER: \newcommand{\pt}{p_{\theta}}
#+LATEX_HEADER: \newcommand{\QQ}{\boldsymbol{Q}}

~===~
title: My notes on discrete denoising diffusion models (D3PMs)
layout: default_latex
~===~

* Denoising discrete diffusion probabilistic models (D3PM)

** Updates:

- (14/07/2022) Thanks to [[https://scholar.google.ca/citations?user=RJos_EEAAAAJ&hl=en][Alex Pich√©]] who spotted a potential error with my derivation in the original version of this blog post. I think the derivation I have is correct now.

** Introduction

Here are some of my thoughts on a (semi-)recent paper that came out by [[https://proceedings.neurips.cc/paper/2021/hash/958c530554f78bcd8e97125b70e6973d-Abstract.html][Austin et al.]] [1]. It proposes a variant of the (continuous) diffusion model for discrete data, which is typically an awkward modality to deal with since almost everything we do with deep neural networks is in continuous space. Many types of data can be represented as discrete, for instance text, molecules, graphs, and even images if we don't dequantise their pixel values (which are typically ordinal variables taking on values (0-255)). Representing data as discrete variables can also be a reasonable form of compression.

In this short blog post I won't be going into all of the details of the paper, but I will be mainly presenting some math I did to help me better understand the proposed algorithm.

#+caption: An overview of D3PMs.
[[file:./d3pms.png]]

** Characterisation of the reverse process

Probably the most confusing aspect of the paper for me was Section 3.3, which explains how the reverse process $\pt$ is formulated. For some weird and confusing reason (which apparently is empirically justified) instead of just having our neural network $\pt$ predict $\xx_{t-1}$ from $\xx_t$ (i.e. parameterise $\pt(\xx_{t-1} | \xx_{t})$), our neural network learns $\pt(\xx_0 | \xx_t)$ instead in one jump. Then the question is, how do we actually do reverse diffusion iteratively one step at a time?

It took me some time to figure this out, but the key is actually in Equation (3) of [1]. Equation 3 in [1] basically says that for the //forward process// $q$, it is possible to run it in reverse if we condition on $x_0$, which is the following:

\begin{align}
q(\xx_{t-1}|\xx_t, \xx_0) = \frac{q(\xx_t | \xx_{t-1}, \xx_0) q(\xx_{t-1}|\xx_0) }{q(\xx_t | \xx_0)} = \text{Cat}\Big( \xx_{t-1}; \boldsymbol{p} = \frac{\xx_t \QQ_t^{T} \cdot \xx_0 \bar{\QQ}_{t-1}}{\xx_0 \bar{\QQ}_t \xx_{t}^{T}} \Big)
\end{align}

This isn't too surprising if you've read the original diffusion paper [2] which does diffusion in the continuous case with Gaussian distributions. It's a requirement in order for our loss function to be tractable. (For more information on this, I highly recommend [[https://lilianweng.github.io/posts/2021-07-11-diffusion-models/][Lilian Weng's blog on diffusion models]].)

Weirdly enough, we can 'hijack' this equation using our learned reverse processs $\pt(\xx_0|\xx_t)$. From Bayes' rule, we can actually marginalise out $\xx_0$ in Equation (3) in [1] by computing the expectation with respect to $q(\xx_0|\xx_t)$:

\begin{align}
q(\xx_{t-1}|\xx_{t}) & = \frac{\sum_{\xx_0} q(\xx_{t-1}, \xx_t, \xx_0)}{q(\xx_t)} \\
& = \frac{\sum_{\xx_0} q(\xx_{t-1} | \xx_t, \xx_0) q(\xx_0 | \xx_t) q(\xx_t) }{q(\xx_t)} \\
& = \sum_{\xx_0} q(\xx_{t-1} | \xx_t, \xx_0) q(\xx_0 | \xx_t) \\
& = \mathbb{E}_{q(\xx_0|\xx_t)} \ q(\xx_{t-1} | \xx_t, \xx_0)
\end{align}

Note that the expection is over $q(\xx_0|\xx_t)$ which is intractable! What we do have however is our learned //reverse process//, so we can just approximate this term by replacing $q(\xx_0|\xx_t)$ with $\pt(\xx_0|\xx_t)$. I'm gonna call this $q_{\theta}$ since this is an amalgamation of the forward process and our learned reverse process:

\begin{align}
q(\xx_{t-1}|\xx_{t}) \approx \mathbb{E}_{\xx_0 \sim \pt(\xx_0|\xx_t)} \ q(\xx_{t-1} | \xx_{t}, \xx_0) = q_{\theta}(\xx_{t-1}|\xx_{t}).
\end{align}

Taking the expectation on both sides of Equation (3) in [1], we can derive the following:

\begin{align}
\mathbb{E}_{\pt(\xx_0|\xx_t)} \ q(\xx_{t-1}|\xx_t, \xx_0) & = q_{\theta}(\xx_{t-1}|\xx_t) \\
& = \mathbb{E}_{\pt(\xx_0|\xx_t)} \ \frac{q(\xx_t | \xx_{t-1}, \xx_0) q(\xx_{t-1}|\xx_0) }{q(\xx_t | \xx_0)} \\
& = \mathbb{E}_{\pt(\xx_0|\xx_t)} \ \frac{q(\xx_t | \xx_{t-1}) q(\xx_{t-1}|\xx_0) }{q(\xx_t | \xx_0)} \\
& \propto \mathbb{E}_{\pt(\xx_0|\xx_t)} \ q(\xx_t | \xx_{t-1}) q(\xx_{t-1}|\xx_0) \\
& = \sum_{j} \Big[ q(\xx_t | \xx_{t-1}) q(\xx_{t-1} | \xx_0^{(j)}) \pt(\xx_0^{(j)}|\xx_t) \Big] \\
& = q(\xx_t | \xx_{t-1}) \Big[ \sum_{j} q(\xx_{t-1} | \xx_0^{(j)}) \pt(\xx_0^{(j)}|\xx_t) \Big]
\end{align}
Let's run through this line by line:

- In lines 8-9, $q(\xx_t|\xx_{t-1}, \xx_0) = q(\xx_t|\xx_{t-1})$ due to the Markov property.
- In line (10), we are simply omitting the denominator and then saying the left-hand side is proportional to the numerator. This is actually because of how this equation is implemented in code: distributions computed are typically expressed as logits (unnormalised probabilities), so we need not concern ourselves with normalisation here. This lets us focus on the numerator.
- In line (11), we re-write the expectation as a summation. Note that if $\xx$ came from our data distribution $q(\xx_0)$ it would be a one-hot vector, i.e. $\xx_0^{(i)} = 1$ for some $i \in \{1, \dots, k\}$. This means the summation would only be non-zero at $\xx_0^{(i)}$. Here however, since $\xx_0$ is a draw from our reverse model, it is likely putting probability mass over multiple outcomes, and the summation here makes it more explicit that we are doing a weighted sum.
- In line (12), we move $q(\xx_t | \xx_{t-1})$ outside of the summation since there is no dependence on $\xx_0$.

This particular equation is implemented [[https://github.com/google-research/google-research/blob/master/d3pm/images/diffusion_categorical.py#L399-L424][here]] in code, when ~x_start_logits=True~. To be consistent with what's in the code, let us call ~fact1~ (short for 'factor') the $q(\xx_t|\xx_{t-1})$ term and ~fact2~ the summation (expectation) term in line (12).

- ~fact1 = self._at(self.transpose_q_onestep_mats, t, x_t)~. From Equation (1) this function call is implementing $\xx_{t} \QQ_{t}^{T}$.
- ~fact2 = self._at_onehot(self.q_mats, t-1, jax.nn.softmax(x_start, axis=-1)~. From Equation (1) this function call is implementing $\xx_0 \bar{\QQ}_{t-1}$. ~x_start~ here is actually the predicted logits $\tilde{\pt}(\xx_0|\xx_t)$, which subsequently gets normalised with ~jax.nn.softmax(x_start)~.
- Note that the multiplication of both factors is done in log space, so we add the terms, i.e. ~log(fact1*fact2) = log(fact1) + log(fact2)~.

* Conclusion

I thank the original paper author Jacob Austin for addressing a confusion of mine in the code.

That is it for now!

* References

- [1] Austin, J., Johnson, D. D., Ho, J., Tarlow, D., & van den Berg, R. (2021). Structured denoising diffusion models in discrete state-spaces. Advances in Neural Information Processing Systems, 34, 17981-17993.
- [2] Ho, J., Jain, A., & Abbeel, P. (2020). Denoising diffusion probabilistic models. Advances in Neural Information Processing Systems, 33, 6840-6851.













